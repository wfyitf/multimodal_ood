{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for real MMD OOD dataset creation\n",
    "\n",
    "To create the datasets for real MMD OOD data, please follow the procedures listed below:\n",
    "1. **\\[Data Sources\\]** Download dataset from [MMD dataset](https://github.com/shh1574/multi-modal-dialogue-dataset/) with the [link](https://drive.google.com/drive/folders/12-Zz4MJTASJVlbncpSWvBVqLDe5_m5QU), also download COCO2014 dataset(https://cocodataset.org/#home) and put them under `dataset/mmd` and `dataset/coco`, respectively. The COCO data structure will be looking like below:\n",
    "```\n",
    "├─── dataset                    <- Main dataset folder\n",
    "│   ├─── coco                   <- COCO2014 Dataset\n",
    "│   │    ├─── coco_annotations  <- image annotations\n",
    "│   │    ├─── train2014         <- train images\n",
    "│   │    ├─── val2014           <- val images\n",
    "```\n",
    "The mmd data structure will be as follows:\n",
    "```\n",
    "├─── dataset                    <- Main dataset folder\n",
    "│   ├─── mmd                    <- MMD Dataset\n",
    "│   │    ├─── dev               <- validation split\n",
    "│   │    ├─── test              <- test split\n",
    "│   │    ├─── train             <- train split\n",
    "│   │    ├─── sample            <- processed target dir\n",
    "```\n",
    "2. **\\[Dataset Generation\\]** Run this notebook to create the Real OOD dataset. Then the dialogue and label data can be found under `dataset/realmmd/sample.json` and the corresponding images can be found under the directory `dataset/realmmd/images`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset directory already exists.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json \n",
    "import sys \n",
    "import re\n",
    "import shutil\n",
    "import json \n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "current_dir = os.getcwd()\n",
    "dataset_dir = os.path.join(os.path.dirname(current_dir), 'dataset')\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "else:\n",
    "    print('dataset directory already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO2014_VAL_DIR = f'{dataset_dir}/coco/val2014'\n",
    "COCO2014_TRAIN_DIR = f'{dataset_dir}/coco/train2014'\n",
    "COCO2014_ANNOTATIONS_DIR = f'{dataset_dir}/coco/coco_annotations'\n",
    "MMD_VAL_DIR = f'{dataset_dir}/mmd/dev'\n",
    "MMD_TRAIN_DIR = f'{dataset_dir}/mmd/train'\n",
    "MMD_TEST_DIR = f'{dataset_dir}/mmd/test'\n",
    "TARGET_DIR = f'{dataset_dir}/realmmd'\n",
    "TARGET_IMAGE_DIR = f'{dataset_dir}/realmmd/images'\n",
    "\n",
    "if not os.path.exists(TARGET_DIR):\n",
    "    os.makedirs(TARGET_DIR)\n",
    "    os.makedirs(TARGET_IMAGE_DIR)\n",
    "\n",
    "def extract_pattern(s):\n",
    "    match = re.search(r'COCO_(.*?)_\\d+', s)\n",
    "    if match:\n",
    "        return match.group(1)  \n",
    "    return None  \n",
    "\n",
    "def create_complex_index(s):\n",
    "    parts = s.split('_')\n",
    "    if 'train' in parts[1]:\n",
    "        type_code = 1 \n",
    "    elif 'val' in parts[1]:\n",
    "        type_code = 2 \n",
    "    else:\n",
    "        type_code = 3 \n",
    "    id_str = parts[2][:-4] \n",
    "    index = int(f\"{type_code}{id_str}\")\n",
    "    return index\n",
    "\n",
    "def process_and_copy_image(row):\n",
    "    if row['set_source'] == 'val2014':\n",
    "        source_dir = COCO2014_VAL_DIR\n",
    "    elif row['set_source'] == 'train2014':\n",
    "        source_dir = COCO2014_TRAIN_DIR\n",
    "    else:\n",
    "        raise ValueError(\"Unknown set_source\")\n",
    "    \n",
    "    try:\n",
    "        new_index = row['image_id']\n",
    "        new_filename = f\"{new_index}.jpg\"\n",
    "        \n",
    "        source_path = os.path.join(source_dir, row['img_file'])\n",
    "        target_path = os.path.join(TARGET_IMAGE_DIR, new_filename)\n",
    "        \n",
    "        shutil.copy(source_path, target_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "def create_img_index(s):\n",
    "    parts = s.split('_')\n",
    "    id_str = parts[2][:-4] \n",
    "    index = int(id_str)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Json files for annotations\n",
    "val_json = pd.read_json(MMD_VAL_DIR + '/dev.json')\n",
    "train_json = pd.read_json(MMD_TRAIN_DIR + '/train.json')\n",
    "test_json = pd.read_json(MMD_TEST_DIR + '/test.json')\n",
    "\n",
    "# Combine all json files to get the total json\n",
    "total_json = pd.concat([val_json, train_json, test_json], ignore_index=True)\n",
    "coco_mmd = total_json[total_json['img_dataset'] == 'coco'].copy()\n",
    "coco_mmd['set_source'] = coco_mmd['img_file'].apply(extract_pattern)\n",
    "coco_mmd = coco_mmd.drop(columns=['replaced_idx', 'img_idx'])\n",
    "coco_mmd['image_id'] = coco_mmd['img_file'].apply(create_complex_index)\n",
    "coco_label_val = json.load(open(COCO2014_ANNOTATIONS_DIR + '/instances_val2014.json'))\n",
    "coco_label_train = json.load(open(COCO2014_ANNOTATIONS_DIR + '/instances_train2014.json'))\n",
    "coco_label_val_ann = pd.DataFrame(coco_label_val['annotations'])\n",
    "coco_label_train_ann = pd.DataFrame(coco_label_train['annotations'])\n",
    "label_df = pd.DataFrame(coco_label_val['categories'])\n",
    "label_df = label_df.rename(columns={'id': 'category_id'})\n",
    "\n",
    "# Merge the labels with the annotations\n",
    "coco_label_val_ann = coco_label_val_ann.merge(label_df, on='category_id')\n",
    "val_grouped_categories = coco_label_val_ann.groupby('image_id')['name'].unique().apply(list).reset_index()\n",
    "val_grouped_supercategories = coco_label_val_ann.groupby('image_id')['supercategory'].unique().reset_index()\n",
    "val_categories = val_grouped_categories.merge(val_grouped_supercategories, on='image_id')\n",
    "val_categories['set_source'] = 'val2014'\n",
    "\n",
    "# Merge the labels with the annotations\n",
    "coco_label_train_ann = coco_label_train_ann.merge(label_df, on='category_id')\n",
    "train_grouped_categories = coco_label_train_ann.groupby('image_id')['name'].unique().apply(list).reset_index()\n",
    "train_grouped_supercategories = coco_label_train_ann.groupby('image_id')['supercategory'].unique().reset_index()\n",
    "train_categories = train_grouped_categories.merge(train_grouped_supercategories, on='image_id')\n",
    "train_categories['set_source'] = 'train2014'\n",
    "\n",
    "# Combine the categories\n",
    "overall_categories = pd.concat([val_categories, \n",
    "                                train_categories], \n",
    "                               ignore_index=True)\n",
    "\n",
    "overall_categories = overall_categories.rename(columns={'name': 'categories', \n",
    "                                                        'supercategory': 'supercategories'})\n",
    "\n",
    "# Merge the categories with the coco_mmd and copy the images\n",
    "coco_mmd['image_idx'] = coco_mmd['img_file'].apply(create_img_index)\n",
    "overall_categories = overall_categories.rename(columns={'image_id': 'image_idx'})\n",
    "coco_mmd = coco_mmd.merge(overall_categories, on=['image_idx', 'set_source'])\n",
    "coco_mmd.to_json(TARGET_DIR + '/sample.json', orient='records')\n",
    "coco_mmd['copy_status'] = coco_mmd.apply(process_and_copy_image, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial-recgonition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
