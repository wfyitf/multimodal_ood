{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json \n",
    "import sys \n",
    "import re\n",
    "import shutil\n",
    "import json \n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "current_dir = os.getcwd()\n",
    "dataset_dir = os.path.join(os.path.dirname(current_dir), 'dataset')\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "else:\n",
    "    print('dataset directory already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is for creating the real OOD MMD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO2014_VAL_DIR = f'{dataset_dir}/coco/val2014'\n",
    "COCO2014_TRAIN_DIR = f'{dataset_dir}/coco/train2014'\n",
    "COCO2014_ANNOTATIONS_DIR = f'{dataset_dir}/coco/coo_annotations'\n",
    "VISDIAL_DIR = f'{dataset_dir}/visdial'\n",
    "VISDIAL_ANNOTATIONS_DIR = f'{dataset_dir}/coco_annotations'\n",
    "TARGET_DIR = f'{dataset_dir}/qa'\n",
    "TARGET_IMAGE_DIR = f'{dataset_dir}/qa/images'\n",
    "\n",
    "if not os.path.exists(TARGET_DIR):\n",
    "    os.makedirs(TARGET_DIR)\n",
    "    os.makedirs(TARGET_IMAGE_DIR)\n",
    "    \n",
    "\n",
    "def process_and_copy_image(row):\n",
    "    if row['set_source'] == 'val2014':\n",
    "        source_dir = COCO2014_VAL_DIR\n",
    "    elif row['set_source'] == 'train2014':\n",
    "        source_dir = COCO2014_TRAIN_DIR\n",
    "    else:\n",
    "        print(f\"Unknown image source: {row['set_source']}, {row['image_id']}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        new_index = row['image_id']\n",
    "        new_filename = f\"{new_index}.jpg\"\n",
    "        \n",
    "        source_path = os.path.join(source_dir, row['file_name'])\n",
    "        target_path = os.path.join(TARGET_IMAGE_DIR, new_filename)\n",
    "        \n",
    "        shutil.copy(source_path, target_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialog = f'{VISDIAL_DIR}/visdial_0.9_train.json'\n",
    "val_dialog = f'{VISDIAL_DIR}/visdial_0.9_val.json'\n",
    "coco_label_val = json.load(open(COCO2014_ANNOTATIONS_DIR + '/instances_val2014.json'))\n",
    "coco_label_train = json.load(open(COCO2014_ANNOTATIONS_DIR + '/instances_train2014.json'))\n",
    "\n",
    "with open(train_dialog, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(val_dialog, 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "    \n",
    "train_question_list = train_data['data']['questions']\n",
    "val_question_list = val_data['data']['questions']\n",
    "train_answer_list = train_data['data']['answers']\n",
    "val_answer_list = val_data['data']['answers']\n",
    "\n",
    "train_df = pd.DataFrame(train_data['data']['dialogs'])\n",
    "val_df = pd.DataFrame(val_data['data']['dialogs'])\n",
    "\n",
    "def generate_train_diag(row):\n",
    "    diag = \"\"\n",
    "    for i in row['dialog']:\n",
    "        diag += \"Q: \" + train_question_list[i['question']] + '\\n' + \"A: \" + train_answer_list[i['answer']] + '\\n'\n",
    "    return diag\n",
    "\n",
    "def generate_val_diag(row):\n",
    "    diag = \"\"\n",
    "    for i in row['dialog']:\n",
    "        diag += \"Q: \" + val_question_list[i['question']] + '\\n' + \"A: \" + val_answer_list[i['answer']] + '\\n'\n",
    "    return diag\n",
    "\n",
    "train_df['dialog_full'] = train_df.apply(generate_train_diag, axis=1)\n",
    "val_df['dialog_full'] = val_df.apply(generate_val_diag, axis=1)\n",
    "\n",
    "train_df['dialog_full'] = train_df.apply(generate_train_diag, axis=1)\n",
    "val_df['dialog_full'] = val_df.apply(generate_val_diag, axis=1)\n",
    "\n",
    "train_df['file_name'] = train_df['image_id'].apply(lambda x: f'COCO_train2014_{str(x).zfill(12)}.jpg')\n",
    "val_df['file_name'] = val_df['image_id'].apply(lambda x: f'COCO_val2014_{str(x).zfill(12)}.jpg')\n",
    "\n",
    "coco_label_val_ann = pd.DataFrame(coco_label_val['annotations'])\n",
    "coco_label_train_ann = pd.DataFrame(coco_label_train['annotations'])\n",
    "\n",
    "label_df = pd.DataFrame(coco_label_val['categories'])\n",
    "label_df = label_df.rename(columns={'id': 'category_id'})\n",
    "\n",
    "# Merge the labels with the annotations\n",
    "coco_label_val_ann = coco_label_val_ann.merge(label_df, on='category_id')\n",
    "val_grouped_categories = coco_label_val_ann.groupby('image_id')['name'].unique().apply(list).reset_index()\n",
    "val_grouped_supercategories = coco_label_val_ann.groupby('image_id')['supercategory'].unique().reset_index()\n",
    "val_categories = val_grouped_categories.merge(val_grouped_supercategories, on='image_id')\n",
    "val_categories['set_source'] = 'val2014'\n",
    "\n",
    "# Merge the labels with the annotations\n",
    "coco_label_train_ann = coco_label_train_ann.merge(label_df, on='category_id')\n",
    "train_grouped_categories = coco_label_train_ann.groupby('image_id')['name'].unique().apply(list).reset_index()\n",
    "train_grouped_supercategories = coco_label_train_ann.groupby('image_id')['supercategory'].unique().reset_index()\n",
    "train_categories = train_grouped_categories.merge(train_grouped_supercategories, on='image_id')\n",
    "train_categories['set_source'] = 'train2014'\n",
    "\n",
    "train_df = train_df.merge(train_categories, left_on='image_id', right_on='image_id', how='left')\n",
    "val_df = val_df.merge(val_categories, left_on='image_id', right_on='image_id', how='left')\n",
    "\n",
    "overall_df = pd.concat([train_df, val_df], axis=0)\n",
    "overall_df = overall_df[overall_df['set_source'].notnull()]\n",
    "overall_df.to_json(TARGET_DIR + '/sample.json', orient='records')\n",
    "overall_df['copy_status'] = overall_df.apply(process_and_copy_image, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial-recgonition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
