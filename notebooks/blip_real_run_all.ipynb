{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json \n",
    "import sys \n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "import loaders\n",
    "from utils import scores as sc\n",
    "from utils import evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set Logger\n",
    "logger = logging.getLogger('notebook_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing one example\n",
    "data_loader = loaders.DataLoader(data_source = \"real\", logger=logger)\n",
    "df_table_origin = data_loader.load_annotations_df()\n",
    "\n",
    "#k = 5\n",
    "#data_loader.showing_example(k)\n",
    "#data_loader.show_clip_similarity(k, df_table, model, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define OOD Categories below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CLIP features for images and dialogues with Model CLIP ViT-B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:22:42,066 - notebook_logger - INFO - Processing OOD Category: animal\n",
      "2024-08-04 17:22:43,251 - notebook_logger - INFO - Calculating Similarity Scores\n",
      "2024-08-04 17:22:43,489 - notebook_logger - INFO - Setting random seed: 20\n",
      "2024-08-04 17:22:43,491 - notebook_logger - INFO - Setting random seed: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models.DNN import model \n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "used_model = \"blip\"\n",
    "\n",
    "if used_model == \"clip\":\n",
    "    input_size = 512\n",
    "elif used_model == \"blip\":\n",
    "    input_size = 256\n",
    "\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "category = \"animal\"\n",
    "logger.info(f\"Processing OOD Category: {category}\")\n",
    "ood_category = [category]\n",
    "ind_category = [x for x in data_loader.supercategories if x not in ood_category]\n",
    "\n",
    "df_table = df_table_origin.copy()\n",
    "df_table['OOD'] = df_table['supercategories'].apply(lambda x: 0 if any(item in x for item in ood_category) else 1)\n",
    "df_table['OOD'].value_counts()\n",
    "\n",
    "if data_loader.data_source == \"real\":\n",
    "    dialogue_clip = np.load(f'{data_loader.data_dir}/CLIP/mmd_dialogs_truncate/mmd_clip_dialog_features.npy')\n",
    "    df_table['dialogue_clip'] = list(dialogue_clip)\n",
    "    image_clip = np.load(f'{data_loader.data_dir}/CLIP/mmd_imgs/mmd_clip_img_features.npy')\n",
    "    image_annotation = pd.read_json(f'{data_loader.data_dir}/CLIP/mmd_imgs/mmd_imgs_filenames.json')\n",
    "    image_annotation = image_annotation.rename(columns={0:\"img_file\"}).join(pd.DataFrame(pd.DataFrame(image_clip.tolist()).apply(np.array, axis=1)))\n",
    "    image_annotation.rename(columns={0:\"image_clip\"}, inplace=True)\n",
    "    df_table = df_table.merge(image_annotation, on='img_file', how='left')\n",
    "\n",
    "elif data_loader.data_source == \"qa\":\n",
    "    dialogue_clip = np.load(f'{data_loader.data_dir}/CLIP/qa_dialogs_truncate/qa_clip_dialog_features_single.npy')\n",
    "    df_table['dialogue_clip'] = list(dialogue_clip)\n",
    "    df_table['image_file'] = df_table['image_id'].astype('str') + '.jpg'\n",
    "    image_clip = np.load(f'{data_loader.data_dir}/CLIP/qa_imgs/qa_clip_img_features.npy')\n",
    "    image_annotation = pd.read_json(f'{data_loader.data_dir}/CLIP/qa_imgs/all_img_names.json')\n",
    "    image_annotation = image_annotation.rename(columns={0:\"image_file\"})\n",
    "    image_annotation['image_clip'] = list(image_clip)\n",
    "    df_table = df_table.merge(image_annotation, on='image_file', how='left') \n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=ind_category)\n",
    "df_table['encoded_label'] = list(mlb.fit_transform(df_table['supercategories']))\n",
    "encoded_df = pd.DataFrame(df_table['encoded_label'].tolist(), columns=ind_category)\n",
    "df_table = pd.concat([df_table, encoded_df], axis=1)\n",
    "\n",
    "logger.info(f\"Calculating Similarity Scores\")\n",
    "\n",
    "def image_text_similarity(row):\n",
    "    a = row['dialogue_clip']\n",
    "    b = row['image_clip']\n",
    "    cos_sim = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "df_table['image_text_similarity'] = df_table.apply(image_text_similarity, axis=1)\n",
    "\n",
    "image_model_loader = model.model_loader(logger=logger,\n",
    "                                input_size=input_size,\n",
    "                                output_size=len(ind_category),\n",
    "                                num_epochs=6,\n",
    "                                learning_rate=0.001,\n",
    "                                proportion = 0.8,\n",
    "                                seed = 20)\n",
    "\n",
    "dialogue_model_loader = model.model_loader(logger=logger,\n",
    "                                input_size=input_size,\n",
    "                                output_size=len(ind_category),\n",
    "                                num_epochs=6,\n",
    "                                learning_rate=0.001,\n",
    "                                seed = 20)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]2024-08-04 17:22:55,426 - notebook_logger - INFO - Epoch 1, Train Loss: 0.2585, Train Accuracy: 0.2747, Test Loss: 0.2576, Test Accuracy: 0.3073\n",
      " 17%|█▋        | 1/6 [00:01<00:09,  1.88s/it]2024-08-04 17:22:57,214 - notebook_logger - INFO - Epoch 2, Train Loss: 0.1989, Train Accuracy: 0.4386, Test Loss: 0.2464, Test Accuracy: 0.3364\n",
      " 33%|███▎      | 2/6 [00:03<00:07,  1.83s/it]2024-08-04 17:22:59,098 - notebook_logger - INFO - Epoch 3, Train Loss: 0.1661, Train Accuracy: 0.5337, Test Loss: 0.2243, Test Accuracy: 0.4038\n",
      " 50%|█████     | 3/6 [00:05<00:05,  1.85s/it]2024-08-04 17:23:00,944 - notebook_logger - INFO - Epoch 4, Train Loss: 0.1366, Train Accuracy: 0.6182, Test Loss: 0.2407, Test Accuracy: 0.3850\n",
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.85s/it]2024-08-04 17:23:02,892 - notebook_logger - INFO - Epoch 5, Train Loss: 0.1084, Train Accuracy: 0.7091, Test Loss: 0.2384, Test Accuracy: 0.4307\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.89s/it]2024-08-04 17:23:04,726 - notebook_logger - INFO - Epoch 6, Train Loss: 0.0941, Train Accuracy: 0.7419, Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.86s/it]\n",
      "2024-08-04 17:23:04,730 - notebook_logger - INFO - Model saved at f:\\Github\\multimodal_ood\\models\\DNN\\models\\DNN\\image_model_animal_6_0.001.pth\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]2024-08-04 17:23:06,558 - notebook_logger - INFO - Epoch 1, Train Loss: 0.4795, Train Accuracy: 0.0081, Test Loss: 0.4107, Test Accuracy: 0.0537\n",
      " 17%|█▋        | 1/6 [00:01<00:09,  1.82s/it]2024-08-04 17:23:08,372 - notebook_logger - INFO - Epoch 2, Train Loss: 0.4794, Train Accuracy: 0.0081, Test Loss: 0.4058, Test Accuracy: 0.0537\n",
      " 33%|███▎      | 2/6 [00:03<00:07,  1.82s/it]2024-08-04 17:23:10,236 - notebook_logger - INFO - Epoch 3, Train Loss: 0.4784, Train Accuracy: 0.0081, Test Loss: 0.4124, Test Accuracy: 0.0537\n",
      " 50%|█████     | 3/6 [00:05<00:05,  1.84s/it]2024-08-04 17:23:12,068 - notebook_logger - INFO - Epoch 4, Train Loss: 0.4775, Train Accuracy: 0.0081, Test Loss: 0.4098, Test Accuracy: 0.0537\n",
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.84s/it]2024-08-04 17:23:13,917 - notebook_logger - INFO - Epoch 5, Train Loss: 0.4769, Train Accuracy: 0.0081, Test Loss: 0.4089, Test Accuracy: 0.0537\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.84s/it]2024-08-04 17:23:15,834 - notebook_logger - INFO - Epoch 6, Train Loss: 0.4769, Train Accuracy: 0.0033, Test Loss: 0.4097, Test Accuracy: 0.0984\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.85s/it]\n",
      "2024-08-04 17:23:15,837 - notebook_logger - INFO - Model saved at f:\\Github\\multimodal_ood\\models\\DNN\\models\\DNN\\image_model_animal_6_0.001.pth\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "df_ind_train, \n",
    "df_test, \n",
    "X_train_image, \n",
    "X_test_image, \n",
    "X_train_dialogue, \n",
    "X_test_dialogue, \n",
    "Y_train, \n",
    "Y_test) = image_model_loader.create_dataset(data_loader, df_table, add_mismatch = True, mismatch_num = 3000)\n",
    "\n",
    "df_test['image_text_similarity'] = df_test.apply(image_text_similarity, axis=1)\n",
    "image_model_loader.train_model(X_train_image, Y_train, X_test_image, Y_test, ood_category = '_'.join(ood_category))\n",
    "dialogue_model_loader.train_model(X_train_dialogue, Y_train, X_test_dialogue, Y_test, ood_category = '_'.join(ood_category))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:24:26,569 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:24:26,846 - notebook_logger - INFO - Test Loss: 0.4097, Test Accuracy: 0.0984\n",
      "2024-08-04 17:24:27,139 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:24:27,437 - notebook_logger - INFO - Test Loss: 0.4097, Test Accuracy: 0.0984\n",
      "2024-08-04 17:24:27,735 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:24:28,042 - notebook_logger - INFO - Test Loss: 0.4097, Test Accuracy: 0.0984\n",
      "2024-08-04 17:24:28,326 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:24:28,610 - notebook_logger - INFO - Test Loss: 0.4097, Test Accuracy: 0.0984\n",
      "2024-08-04 17:24:29,815 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:24:30,985 - notebook_logger - INFO - Test Loss: 0.4097, Test Accuracy: 0.0984\n",
      "2024-08-04 17:25:05,305 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n"
     ]
    }
   ],
   "source": [
    "score_type_list = [\"prob\", \"energy\", \"logits\", \"msp\", \"odin\", \"mahalanobis\"]\n",
    "for score_type in score_type_list:\n",
    "    if score_type != \"mahalanobis\":\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "\n",
    "    else:\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_image,\n",
    "                                                            Y_train=Y_train)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_dialogue,\n",
    "                                                            Y_train=Y_train)\n",
    "    \n",
    "    df_test[f'{score_type}_sum_image'] = image_score_sum\n",
    "    df_test[f'{score_type}_max_image'] = image_score_max\n",
    "    df_test[f'{score_type}_sum_dialogue'] = dialogue_score_sum\n",
    "    df_test[f'{score_type}_max_dialogue'] = dialogue_score_max\n",
    "    if score_type in [\"energy\", \"logits\", \"prob\", \"odin\", \"mahalanobis\"]:\n",
    "        df_test[f'{score_type}_overall_simialrity_sum'] = df_test[f'{score_type}_sum_image'] + df_test[f'{score_type}_sum_dialogue']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_type_list = [\"prob\", \"energy\", \"logits\", \"msp\", \"odin\", \"mahalanobis\"]\n",
    "\n",
    "for score_type in score_type_list:\n",
    "    if score_type != \"mahalanobis\":\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "\n",
    "    else:\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_image,\n",
    "                                                            Y_train=Y_train)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_dialogue,\n",
    "                                                            Y_train=Y_train)\n",
    "    \n",
    "    df_test[f'{score_type}_sum_image'] = image_score_sum\n",
    "    df_test[f'{score_type}_max_image'] = image_score_max\n",
    "    df_test[f'{score_type}_sum_dialogue'] = dialogue_score_sum\n",
    "    df_test[f'{score_type}_max_dialogue'] = dialogue_score_max\n",
    "    if score_type == \"mahalanobis\":\n",
    "        df_test[f'{score_type}_max_image_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_max_image'] \n",
    "        df_test[f'{score_type}_max_dialogue_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_max_dialogue']\n",
    "        df_test[f'{score_type}_sum_image_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_sum_image']\n",
    "        df_test[f'{score_type}_sum_dialogue_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_sum_dialogue'] \n",
    "    else:\n",
    "        df_test[f'{score_type}_max_image_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_max_image'] \n",
    "        df_test[f'{score_type}_max_dialogue_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_max_dialogue']\n",
    "        df_test[f'{score_type}_sum_image_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_sum_image']\n",
    "        df_test[f'{score_type}_sum_dialogue_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_sum_dialogue']\n",
    "    df_test[f'{score_type}_overall_simialrity_max'] = df_test[f'{score_type}_max_image'] + df_test[f'{score_type}_max_dialogue']\n",
    "    df_test[f'{score_type}_overall_simialrity_max_transform'] =  df_test[f'{score_type}_max_image_tranform'] + df_test[f'{score_type}_max_dialogue_tranform']\n",
    "    if score_type in [\"energy\", \"logits\", \"prob\", \"odin\", \"mahalanobis\"]:\n",
    "        df_test[f'{score_type}_overall_simialrity_sum'] = df_test[f'{score_type}_sum_image'] + df_test[f'{score_type}_sum_dialogue']\n",
    "        df_test[f'{score_type}_overall_simialrity_sum_transform'] = df_test[f'{score_type}_sum_image_tranform'] + df_test[f'{score_type}_sum_dialogue_tranform']\n",
    "\n",
    "\n",
    "# Initialize lists to store data\n",
    "metrics = []\n",
    "values = []\n",
    "scores = [] \n",
    "\n",
    "def eval_dict(score):\n",
    "    return {\n",
    "        \"FPR\": lambda x: ev.fpr_evaluation(x['OOD'].values, x[score].values, 0.95),\n",
    "        \"AUROC\": lambda x: ev.auroc_evaluation(x['OOD'].values, x[score].values),\n",
    "        \"AUPR\": lambda x: ev.aupr_evaluation(x['OOD'].values, x[score].values)\n",
    "    }\n",
    "\n",
    "# Define the metrics and corresponding functions\n",
    "metric_functions = {\n",
    "    \"Energy Sum\": {\n",
    "        \"Image\": eval_dict('energy_sum_image'),\n",
    "        \"Dialogue\": eval_dict('energy_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('energy_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('energy_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Energy Max\": {\n",
    "        \"Image\": eval_dict('energy_max_image'),\n",
    "        \"Dialogue\": eval_dict('energy_max_dialogue'),\n",
    "        \"Overall\": eval_dict('energy_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('energy_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"MSP\": {\n",
    "        \"Image\": eval_dict('msp_max_image'),\n",
    "        \"Dialogue\": eval_dict('msp_max_dialogue'),\n",
    "        \"Overall\": eval_dict('msp_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('msp_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Max Prob\": {\n",
    "        \"Image\": eval_dict('prob_max_image'),\n",
    "        \"Dialogue\": eval_dict('prob_max_dialogue'),\n",
    "        \"Overall\": eval_dict('prob_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('prob_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Prob\": {\n",
    "        \"Image\": eval_dict('prob_sum_image'),\n",
    "        \"Dialogue\": eval_dict('prob_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('prob_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('prob_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Odin\": {\n",
    "        \"Image\": eval_dict('odin_max_image'),\n",
    "        \"Dialogue\": eval_dict('odin_max_dialogue'),\n",
    "        \"Overall\": eval_dict('odin_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('odin_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Odin\": {\n",
    "        \"Image\": eval_dict('odin_sum_image'),\n",
    "        \"Dialogue\": eval_dict('odin_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('odin_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('odin_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Mahalanobis\": {\n",
    "        \"Image\": eval_dict('mahalanobis_max_image'),\n",
    "        \"Dialogue\": eval_dict('mahalanobis_max_dialogue'),\n",
    "        \"Overall\": eval_dict('mahalanobis_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('mahalanobis_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Mahalanobis\": {\n",
    "        \"Image\": eval_dict('mahalanobis_sum_image'),\n",
    "        \"Dialogue\": eval_dict('mahalanobis_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('mahalanobis_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('mahalanobis_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Logits\": {\n",
    "        \"Image\": eval_dict('logits_max_image'),\n",
    "        \"Dialogue\": eval_dict('logits_max_dialogue'),\n",
    "        \"Overall\": eval_dict('logits_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('logits_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Logits\": {\n",
    "        \"Image\": eval_dict('logits_sum_image'),\n",
    "        \"Dialogue\": eval_dict('logits_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('logits_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('logits_overall_simialrity_sum_transform')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through each metric and calculate values\n",
    "for score, items in metric_functions.items():\n",
    "    scores.extend([score] * len(items) * 3)\n",
    "    for metric, funcs in items.items():\n",
    "        metrics.extend([metric] * len(funcs))\n",
    "        values.extend([func(df_test) for func in funcs.values()])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"Metric\": metrics, \"Value\": values, \"Score\": scores})\n",
    "df['Value'] = df['Value'].apply(lambda x: round(x, 3))\n",
    "#df_grouped = df.groupby('Metric')['Value'].apply(list).reset_index()\n",
    "result = df.groupby(['Metric', 'Score'])['Value'].agg(list).unstack().transpose()\n",
    "result_df = result[['Image', 'Dialogue', 'Overall', 'Overall_Transform']]\n",
    "result_df.reset_index(inplace=True)\n",
    "order = ['Max Prob', \n",
    "         'Sum Prob', \n",
    "         'Max Logits', \n",
    "         'Sum Logits', \n",
    "         'Max Odin',\n",
    "         'Sum Odin',\n",
    "         'Max Mahalanobis',\n",
    "         'Sum Mahalanobis',\n",
    "         'MSP', \n",
    "         'Energy Sum', \n",
    "         'Energy Max']\n",
    "result_df = result_df.set_index('Score').loc[order].reset_index()\n",
    "def convert_to_percentage(lst):\n",
    "    return ' / '.join(f'{x*100:.1f}' for x in lst)\n",
    "\n",
    "\n",
    "result_df['Image'] = result_df['Image'].apply(convert_to_percentage)\n",
    "result_df['Dialogue'] = result_df['Dialogue'].apply(convert_to_percentage)\n",
    "result_df['Overall'] = result_df['Overall'].apply(convert_to_percentage)\n",
    "result_df['Overall_Transform'] = result_df['Overall_Transform'].apply(convert_to_percentage)\n",
    "\n",
    "latex_table = result_df.to_latex(index=False, column_format='|l|c|c|c|c|', header=[\"Score\", \"Image\", \"Dialogue\", \"Overall\", \"Overall_Transform\"], escape=False)\n",
    "\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
