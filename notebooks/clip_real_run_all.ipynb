{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json \n",
    "import sys \n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "import loaders\n",
    "from utils import scores as sc\n",
    "from utils import evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set Logger\n",
    "logger = logging.getLogger('notebook_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing one example\n",
    "data_loader = loaders.DataLoader(data_source = \"real\", logger=logger)\n",
    "df_table_origin = data_loader.load_annotations_df()\n",
    "\n",
    "#k = 5\n",
    "#data_loader.showing_example(k)\n",
    "#data_loader.show_clip_similarity(k, df_table, model, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define OOD Categories below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CLIP features for images and dialogues with Model CLIP ViT-B32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:34:28,693 - notebook_logger - INFO - Processing OOD Category: animal\n",
      "2024-08-04 17:34:30,040 - notebook_logger - INFO - Calculating Similarity Scores\n",
      "2024-08-04 17:34:30,267 - notebook_logger - INFO - Setting random seed: 20\n",
      "2024-08-04 17:34:30,270 - notebook_logger - INFO - Setting random seed: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models.DNN import model \n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "used_model = \"clip\"\n",
    "\n",
    "if used_model == \"clip\":\n",
    "    input_size = 512\n",
    "elif used_model == \"blip\":\n",
    "    input_size = 256\n",
    "\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "category = \"animal\"\n",
    "logger.info(f\"Processing OOD Category: {category}\")\n",
    "ood_category = [category]\n",
    "ind_category = [x for x in data_loader.supercategories if x not in ood_category]\n",
    "\n",
    "df_table = df_table_origin.copy()\n",
    "df_table['OOD'] = df_table['supercategories'].apply(lambda x: 0 if any(item in x for item in ood_category) else 1)\n",
    "df_table['OOD'].value_counts()\n",
    "\n",
    "if data_loader.data_source == \"real\":\n",
    "    #dialogue_clip = np.load(f'{data_loader.data_dir}/CLIP/mmd_dialogs_truncate/mmd_clip_dialog_features.npy')\n",
    "    dialogue_clip = np.load(f'{data_loader.data_dir}/CLIP/mmd_dialogs_summary/mmd_summary_features.npy')\n",
    "    df_table['dialogue_clip'] = list(dialogue_clip)\n",
    "    image_clip = np.load(f'{data_loader.data_dir}/CLIP/mmd_imgs/mmd_clip_img_features.npy')\n",
    "    image_annotation = pd.read_json(f'{data_loader.data_dir}/CLIP/mmd_imgs/mmd_imgs_filenames.json')\n",
    "    image_annotation = image_annotation.rename(columns={0:\"img_file\"}).join(pd.DataFrame(pd.DataFrame(image_clip.tolist()).apply(np.array, axis=1)))\n",
    "    image_annotation.rename(columns={0:\"image_clip\"}, inplace=True)\n",
    "    df_table = df_table.merge(image_annotation, on='img_file', how='left')\n",
    "\n",
    "elif data_loader.data_source == \"qa\":\n",
    "    dialogue_clip = np.load(f'{data_loader.data_dir}/CLIP/qa_dialogs_truncate/qa_clip_dialog_features_single.npy')\n",
    "    df_table['dialogue_clip'] = list(dialogue_clip)\n",
    "    df_table['image_file'] = df_table['image_id'].astype('str') + '.jpg'\n",
    "    image_clip = np.load(f'{data_loader.data_dir}/CLIP/qa_imgs/qa_clip_img_features.npy')\n",
    "    image_annotation = pd.read_json(f'{data_loader.data_dir}/CLIP/qa_imgs/all_img_names.json')\n",
    "    image_annotation = image_annotation.rename(columns={0:\"image_file\"})\n",
    "    image_annotation['image_clip'] = list(image_clip)\n",
    "    df_table = df_table.merge(image_annotation, on='image_file', how='left') \n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=ind_category)\n",
    "df_table['encoded_label'] = list(mlb.fit_transform(df_table['supercategories']))\n",
    "encoded_df = pd.DataFrame(df_table['encoded_label'].tolist(), columns=ind_category)\n",
    "df_table = pd.concat([df_table, encoded_df], axis=1)\n",
    "\n",
    "logger.info(f\"Calculating Similarity Scores\")\n",
    "\n",
    "def image_text_similarity(row):\n",
    "    a = row['dialogue_clip']\n",
    "    b = row['image_clip']\n",
    "    cos_sim = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "df_table['image_text_similarity'] = df_table.apply(image_text_similarity, axis=1)\n",
    "\n",
    "image_model_loader = model.model_loader(logger=logger,\n",
    "                                input_size=input_size,\n",
    "                                output_size=len(ind_category),\n",
    "                                num_epochs=6,\n",
    "                                learning_rate=0.001,\n",
    "                                proportion = 0.8,\n",
    "                                seed = 20)\n",
    "\n",
    "dialogue_model_loader = model.model_loader(logger=logger,\n",
    "                                input_size=input_size,\n",
    "                                output_size=len(ind_category),\n",
    "                                num_epochs=6,\n",
    "                                learning_rate=0.001,\n",
    "                                seed = 20)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]2024-08-04 17:36:54,911 - notebook_logger - INFO - Epoch 1, Train Loss: 0.2585, Train Accuracy: 0.2747, Test Loss: 0.2576, Test Accuracy: 0.3073\n",
      " 17%|█▋        | 1/6 [00:01<00:09,  1.94s/it]2024-08-04 17:36:56,883 - notebook_logger - INFO - Epoch 2, Train Loss: 0.1989, Train Accuracy: 0.4386, Test Loss: 0.2464, Test Accuracy: 0.3364\n",
      " 33%|███▎      | 2/6 [00:03<00:07,  1.96s/it]2024-08-04 17:36:58,900 - notebook_logger - INFO - Epoch 3, Train Loss: 0.1661, Train Accuracy: 0.5337, Test Loss: 0.2243, Test Accuracy: 0.4038\n",
      " 50%|█████     | 3/6 [00:05<00:05,  1.98s/it]2024-08-04 17:37:00,873 - notebook_logger - INFO - Epoch 4, Train Loss: 0.1366, Train Accuracy: 0.6182, Test Loss: 0.2407, Test Accuracy: 0.3850\n",
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.98s/it]2024-08-04 17:37:02,847 - notebook_logger - INFO - Epoch 5, Train Loss: 0.1084, Train Accuracy: 0.7091, Test Loss: 0.2384, Test Accuracy: 0.4307\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.98s/it]2024-08-04 17:37:04,785 - notebook_logger - INFO - Epoch 6, Train Loss: 0.0941, Train Accuracy: 0.7419, Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.97s/it]\n",
      "2024-08-04 17:37:04,789 - notebook_logger - INFO - Model saved at f:\\Github\\multimodal_ood\\models\\DNN\\models\\DNN\\image_model_animal_6_0.001.pth\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]2024-08-04 17:37:06,693 - notebook_logger - INFO - Epoch 1, Train Loss: 0.4795, Train Accuracy: 0.0081, Test Loss: 0.4112, Test Accuracy: 0.0537\n",
      " 17%|█▋        | 1/6 [00:01<00:09,  1.89s/it]2024-08-04 17:37:08,538 - notebook_logger - INFO - Epoch 2, Train Loss: 0.4794, Train Accuracy: 0.0081, Test Loss: 0.4059, Test Accuracy: 0.0537\n",
      " 33%|███▎      | 2/6 [00:03<00:07,  1.87s/it]2024-08-04 17:37:10,352 - notebook_logger - INFO - Epoch 3, Train Loss: 0.4784, Train Accuracy: 0.0081, Test Loss: 0.4127, Test Accuracy: 0.0537\n",
      " 50%|█████     | 3/6 [00:05<00:05,  1.84s/it]2024-08-04 17:37:12,241 - notebook_logger - INFO - Epoch 4, Train Loss: 0.4773, Train Accuracy: 0.0081, Test Loss: 0.4097, Test Accuracy: 0.0537\n",
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.86s/it]2024-08-04 17:37:13,989 - notebook_logger - INFO - Epoch 5, Train Loss: 0.4767, Train Accuracy: 0.0081, Test Loss: 0.4070, Test Accuracy: 0.0537\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.82s/it]2024-08-04 17:37:15,903 - notebook_logger - INFO - Epoch 6, Train Loss: 0.4762, Train Accuracy: 0.0031, Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.85s/it]\n",
      "2024-08-04 17:37:15,908 - notebook_logger - INFO - Model saved at f:\\Github\\multimodal_ood\\models\\DNN\\models\\DNN\\image_model_animal_6_0.001.pth\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "df_ind_train, \n",
    "df_test, \n",
    "X_train_image, \n",
    "X_test_image, \n",
    "X_train_dialogue, \n",
    "X_test_dialogue, \n",
    "Y_train, \n",
    "Y_test) = image_model_loader.create_dataset(data_loader, df_table, add_mismatch = True, mismatch_num = 3000)\n",
    "\n",
    "df_test['image_text_similarity'] = df_test.apply(image_text_similarity, axis=1)\n",
    "image_model_loader.train_model(X_train_image, Y_train, X_test_image, Y_test, ood_category = '_'.join(ood_category))\n",
    "dialogue_model_loader.train_model(X_train_dialogue, Y_train, X_test_dialogue, Y_test, ood_category = '_'.join(ood_category))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          2.,   0.,   1.,   1.,   2.,   1.,   2.,   1.,   1.,   2.,   3.,\n",
       "          5.,   9.,   3.,  18.,  11.,   7.,  21.,  22.,  32.,  32.,  42.,\n",
       "         43.,  47.,  64.,  60.,  67.,  99., 127., 109., 149., 171., 176.,\n",
       "        188., 209., 246., 268., 275., 318., 341., 358., 413., 397., 389.,\n",
       "        365., 392., 382., 369., 360., 345., 329., 268., 241., 246., 245.,\n",
       "        206., 181., 164., 146., 130., 103.,  88.,  76.,  66.,  60.,  60.,\n",
       "         38.,  34.,  22.,  28.,  25.,  15.,  13.,   9.,  11.,   6.,   3.,\n",
       "          4.,   1.,   4.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
       "          1.]),\n",
       " array([0.03881817, 0.04134365, 0.04386912, 0.0463946 , 0.04892007,\n",
       "        0.05144555, 0.05397102, 0.0564965 , 0.05902197, 0.06154745,\n",
       "        0.06407292, 0.0665984 , 0.06912387, 0.07164935, 0.07417482,\n",
       "        0.0767003 , 0.07922577, 0.08175125, 0.08427672, 0.0868022 ,\n",
       "        0.08932767, 0.09185315, 0.09437862, 0.0969041 , 0.09942957,\n",
       "        0.10195505, 0.10448052, 0.107006  , 0.10953147, 0.11205695,\n",
       "        0.11458242, 0.1171079 , 0.11963337, 0.12215885, 0.12468432,\n",
       "        0.1272098 , 0.12973527, 0.13226075, 0.13478622, 0.1373117 ,\n",
       "        0.13983717, 0.14236265, 0.14488812, 0.1474136 , 0.14993907,\n",
       "        0.15246455, 0.15499002, 0.1575155 , 0.16004097, 0.16256645,\n",
       "        0.16509192, 0.1676174 , 0.17014287, 0.17266835, 0.17519382,\n",
       "        0.1777193 , 0.18024477, 0.18277025, 0.18529572, 0.1878212 ,\n",
       "        0.19034667, 0.19287215, 0.19539762, 0.1979231 , 0.20044857,\n",
       "        0.20297405, 0.20549952, 0.208025  , 0.21055047, 0.21307595,\n",
       "        0.21560142, 0.2181269 , 0.22065237, 0.22317785, 0.22570332,\n",
       "        0.2282288 , 0.23075427, 0.23327975, 0.23580522, 0.2383307 ,\n",
       "        0.24085617, 0.24338165, 0.24590712, 0.2484326 , 0.25095807,\n",
       "        0.25348355, 0.25600902, 0.2585345 , 0.26105997, 0.26358545,\n",
       "        0.26611092, 0.2686364 , 0.27116187, 0.27368735, 0.27621282,\n",
       "        0.2787383 , 0.28126377, 0.28378925, 0.28631472, 0.2888402 ,\n",
       "        0.29136567]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_test['image_text_similarity'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:37:16,426 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:37:16,702 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:37:16,978 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:37:17,249 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:37:17,555 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:37:17,900 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:37:18,180 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:37:18,471 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:37:19,630 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:37:20,737 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:37:53,775 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:38:27,272 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n"
     ]
    }
   ],
   "source": [
    "score_type_list = [\"prob\", \"energy\", \"logits\", \"msp\", \"odin\", \"mahalanobis\"]\n",
    "for score_type in score_type_list:\n",
    "    if score_type != \"mahalanobis\":\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "\n",
    "    else:\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_image,\n",
    "                                                            Y_train=Y_train)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_dialogue,\n",
    "                                                            Y_train=Y_train)\n",
    "    \n",
    "    df_test[f'{score_type}_sum_image'] = image_score_sum\n",
    "    df_test[f'{score_type}_max_image'] = image_score_max\n",
    "    df_test[f'{score_type}_sum_dialogue'] = dialogue_score_sum\n",
    "    df_test[f'{score_type}_max_dialogue'] = dialogue_score_max\n",
    "    if score_type in [\"energy\", \"logits\", \"prob\", \"odin\", \"mahalanobis\"]:\n",
    "        df_test[f'{score_type}_overall_simialrity_sum'] = df_test[f'{score_type}_sum_image'] + df_test[f'{score_type}_sum_dialogue']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:55:38,206 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:55:38,493 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:55:38,811 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:55:39,109 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:55:39,441 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:55:39,730 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:55:40,039 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:55:40,387 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n",
      "2024-08-04 17:55:41,639 - notebook_logger - INFO - Test Loss: 0.2289, Test Accuracy: 0.4339\n",
      "2024-08-04 17:55:42,902 - notebook_logger - INFO - Test Loss: 0.4126, Test Accuracy: 0.0908\n"
     ]
    }
   ],
   "source": [
    "score_type_list = [\"prob\", \"energy\", \"logits\", \"msp\", \"odin\", \"mahalanobis\"]\n",
    "alpha = 0.95\n",
    "gamma = 0.5\n",
    "for score_type in score_type_list:\n",
    "    if score_type != \"mahalanobis\":\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "\n",
    "    else:\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_image,\n",
    "                                                            Y_train=Y_train)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_dialogue,\n",
    "                                                            Y_train=Y_train)\n",
    "    \n",
    "    df_test[f'{score_type}_sum_image'] = image_score_sum\n",
    "    df_test[f'{score_type}_max_image'] = image_score_max\n",
    "    df_test[f'{score_type}_sum_dialogue'] = dialogue_score_sum\n",
    "    df_test[f'{score_type}_max_dialogue'] = dialogue_score_max\n",
    "    if score_type == \"mahalanobis\":\n",
    "        df_test[f'{score_type}_max_image_tranform'] = 4 * (df_test['image_text_similarity'] ** (-1)) * df_test[f'{score_type}_max_image'] \n",
    "        df_test[f'{score_type}_max_dialogue_tranform'] = 4 * (df_test['image_text_similarity'] ** (-1)) * df_test[f'{score_type}_max_dialogue']\n",
    "        df_test[f'{score_type}_sum_image_tranform'] = 4 * (df_test['image_text_similarity'] ** (-1))* df_test[f'{score_type}_sum_image']\n",
    "        df_test[f'{score_type}_sum_dialogue_tranform'] = 4 * (df_test['image_text_similarity'] ** (-1)) * df_test[f'{score_type}_sum_dialogue'] \n",
    "    else:\n",
    "        df_test[f'{score_type}_max_image_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_max_image'] \n",
    "        df_test[f'{score_type}_max_dialogue_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_max_dialogue']\n",
    "        df_test[f'{score_type}_sum_image_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_sum_image']\n",
    "        df_test[f'{score_type}_sum_dialogue_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_sum_dialogue']\n",
    "    df_test[f'{score_type}_overall_simialrity_max'] = alpha * df_test[f'{score_type}_max_image'] + (1-alpha)*df_test[f'{score_type}_max_dialogue']\n",
    "    df_test[f'{score_type}_overall_simialrity_max_transform'] =  alpha*df_test[f'{score_type}_max_image_tranform'] + (1-alpha)*df_test[f'{score_type}_max_dialogue_tranform']\n",
    "    if score_type in [\"energy\", \"logits\", \"prob\", \"odin\", \"mahalanobis\"]:\n",
    "        df_test[f'{score_type}_overall_simialrity_sum'] = alpha*df_test[f'{score_type}_sum_image'] + (1-alpha)*df_test[f'{score_type}_sum_dialogue']\n",
    "        df_test[f'{score_type}_overall_simialrity_sum_transform'] = alpha*df_test[f'{score_type}_sum_image_tranform'] + (1-alpha)*df_test[f'{score_type}_sum_dialogue_tranform']\n",
    "\n",
    "\n",
    "# Initialize lists to store data\n",
    "metrics = []\n",
    "values = []\n",
    "scores = [] \n",
    "\n",
    "def eval_dict(score):\n",
    "    return {\n",
    "        \"FPR\": lambda x: ev.fpr_evaluation(x['OOD'].values, x[score].values, 0.95),\n",
    "        \"AUROC\": lambda x: ev.auroc_evaluation(x['OOD'].values, x[score].values),\n",
    "        \"AUPR\": lambda x: ev.aupr_evaluation(x['OOD'].values, x[score].values)\n",
    "    }\n",
    "\n",
    "# Define the metrics and corresponding functions\n",
    "metric_functions = {\n",
    "    \"Energy Sum\": {\n",
    "        \"Image\": eval_dict('energy_sum_image'),\n",
    "        \"Dialogue\": eval_dict('energy_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('energy_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('energy_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Energy Max\": {\n",
    "        \"Image\": eval_dict('energy_max_image'),\n",
    "        \"Dialogue\": eval_dict('energy_max_dialogue'),\n",
    "        \"Overall\": eval_dict('energy_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('energy_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"MSP\": {\n",
    "        \"Image\": eval_dict('msp_max_image'),\n",
    "        \"Dialogue\": eval_dict('msp_max_dialogue'),\n",
    "        \"Overall\": eval_dict('msp_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('msp_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Max Prob\": {\n",
    "        \"Image\": eval_dict('prob_max_image'),\n",
    "        \"Dialogue\": eval_dict('prob_max_dialogue'),\n",
    "        \"Overall\": eval_dict('prob_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('prob_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Prob\": {\n",
    "        \"Image\": eval_dict('prob_sum_image'),\n",
    "        \"Dialogue\": eval_dict('prob_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('prob_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('prob_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Odin\": {\n",
    "        \"Image\": eval_dict('odin_max_image'),\n",
    "        \"Dialogue\": eval_dict('odin_max_dialogue'),\n",
    "        \"Overall\": eval_dict('odin_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('odin_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Odin\": {\n",
    "        \"Image\": eval_dict('odin_sum_image'),\n",
    "        \"Dialogue\": eval_dict('odin_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('odin_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('odin_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Mahalanobis\": {\n",
    "        \"Image\": eval_dict('mahalanobis_max_image'),\n",
    "        \"Dialogue\": eval_dict('mahalanobis_max_dialogue'),\n",
    "        \"Overall\": eval_dict('mahalanobis_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('mahalanobis_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Mahalanobis\": {\n",
    "        \"Image\": eval_dict('mahalanobis_sum_image'),\n",
    "        \"Dialogue\": eval_dict('mahalanobis_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('mahalanobis_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('mahalanobis_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Logits\": {\n",
    "        \"Image\": eval_dict('logits_max_image'),\n",
    "        \"Dialogue\": eval_dict('logits_max_dialogue'),\n",
    "        \"Overall\": eval_dict('logits_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('logits_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Logits\": {\n",
    "        \"Image\": eval_dict('logits_sum_image'),\n",
    "        \"Dialogue\": eval_dict('logits_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('logits_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('logits_overall_simialrity_sum_transform')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through each metric and calculate values\n",
    "for score, items in metric_functions.items():\n",
    "    scores.extend([score] * len(items) * 3)\n",
    "    for metric, funcs in items.items():\n",
    "        metrics.extend([metric] * len(funcs))\n",
    "        values.extend([func(df_test) for func in funcs.values()])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"Metric\": metrics, \"Value\": values, \"Score\": scores})\n",
    "df['Value'] = df['Value'].apply(lambda x: round(x, 3))\n",
    "#df_grouped = df.groupby('Metric')['Value'].apply(list).reset_index()\n",
    "result = df.groupby(['Metric', 'Score'])['Value'].agg(list).unstack().transpose()\n",
    "result_df = result[['Image', 'Dialogue', 'Overall', 'Overall_Transform']]\n",
    "result_df.reset_index(inplace=True)\n",
    "order = ['Max Prob', \n",
    "         'Sum Prob', \n",
    "         'Max Logits', \n",
    "         'Sum Logits', \n",
    "         'Max Odin',\n",
    "         'Sum Odin',\n",
    "         'Max Mahalanobis',\n",
    "         'Sum Mahalanobis',\n",
    "         'MSP', \n",
    "         'Energy Sum', \n",
    "         'Energy Max']\n",
    "result_df = result_df.set_index('Score').loc[order].reset_index()\n",
    "def convert_to_percentage(lst):\n",
    "    return ' / '.join(f'{x*100:.1f}' for x in lst)\n",
    "\n",
    "\n",
    "result_df['Image'] = result_df['Image'].apply(convert_to_percentage)\n",
    "result_df['Dialogue'] = result_df['Dialogue'].apply(convert_to_percentage)\n",
    "result_df['Overall'] = result_df['Overall'].apply(convert_to_percentage)\n",
    "result_df['Overall_Transform'] = result_df['Overall_Transform'].apply(convert_to_percentage)\n",
    "\n",
    "latex_table = result_df.to_latex(index=False, column_format='|l|c|c|c|c|', header=[\"Score\", \"Image\", \"Dialogue\", \"Overall\", \"Overall_Transform\"], escape=False)\n",
    "\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
