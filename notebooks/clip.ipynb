{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json \n",
    "import sys \n",
    "from PIL import Image\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "import loaders\n",
    "from utils import scores as sc\n",
    "from utils import evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set Logger\n",
    "logger = logging.getLogger('notebook_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing one example\n",
    "# TODO: Add VSNR for cosine similarity\n",
    "data_loader = loaders.DataLoader(data_source = \"real\", logger=logger)\n",
    "df_table = data_loader.load_dialogue_df()\n",
    "k = 5\n",
    "data_loader.showing_example(k)\n",
    "data_loader.show_clip_similarity(k, df_table, model, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_category = ['vehicle']\n",
    "ind_category = [x for x in data_loader.supercategories if x not in ood_category]\n",
    "df_table['OOD'] = df_table['supercategories'].apply(lambda x: 0 if any(item in x for item in ind_category) else 1)\n",
    "df_table['OOD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dialogue Processing\n",
    "dialogue_clip = np.load(f'{data_loader.data_dir}/CLIP/mmd_dialogs_truncate/mmd_clip_dialog_features.npy')\n",
    "df_table['dialogue_clip'] = list(dialogue_clip)\n",
    "\n",
    "## Image Processing\n",
    "image_clip = np.load(f'{data_loader.data_dir}/CLIP/mmd_imgs/mmd_clip_img_features.npy')\n",
    "image_annotation = pd.read_json(f'{data_loader.data_dir}/CLIP/mmd_imgs/mmd_imgs_filenames.json')\n",
    "image_annotation = image_annotation.rename(columns={0:\"img_file\"}).join(pd.DataFrame(pd.DataFrame(image_clip.tolist()).apply(np.array, axis=1)))\n",
    "image_annotation.rename(columns={0:\"image_clip\"}, inplace=True)\n",
    "df_table = df_table.merge(image_annotation, on='img_file', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=ind_category)\n",
    "df_table['encoded_label'] = list(mlb.fit_transform(df_table['supercategories']))\n",
    "encoded_df = pd.DataFrame(df_table['encoded_label'].tolist(), columns=ind_category)\n",
    "df_table = pd.concat([df_table, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(df_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Category of food'\n",
    "text_tokens = clip.tokenize([text]).to(device)  \n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "if data_loader.data_source == \"qa\":\n",
    "    df_table['image_id'] = df_table['image_id'].apply(lambda x: f\"COCO_train2014_{int(x):012d}\")\n",
    "\n",
    "categories_clip = {}\n",
    "for categories in ind_category:\n",
    "    text = 'Category ' + categories\n",
    "    text_tokens = clip.tokenize([text]).to(device)  \n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_tokens).flatten().cpu().numpy()\n",
    "        categories_clip[categories] = text_features\n",
    "\n",
    "def calculate_similarity_score(row, type = \"image\"):\n",
    "    if type == \"image\":\n",
    "        column = 'image_clip'\n",
    "    elif type == \"dialogue\":\n",
    "        column = 'dialogue_clip'\n",
    "\n",
    "    cosine_sim = 0\n",
    "    cosine_sim_max = 0\n",
    "    for categories in ind_category:\n",
    "        text_features = categories_clip[categories]\n",
    "        cosine_sim_current = np.dot(text_features, row[column]) / (np.linalg.norm(text_features) * np.linalg.norm(row[column]))\n",
    "        cosine_sim += np.exp(10*cosine_sim_current)\n",
    "        cosine_sim_max = max(cosine_sim_max, cosine_sim_current)\n",
    "\n",
    "\n",
    "    return cosine_sim, cosine_sim_max\n",
    "\n",
    "df_table['image_score'], df_table['image_score_max'] = zip(*df_table.progress_apply(calculate_similarity_score, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_table['dialogue_score'], df_table['dialogue_score_max'] = zip(*df_table.progress_apply(calculate_similarity_score, axis=1, args=('dialogue',)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ood_scores = df_table[df_table['OOD'] == 1]['image_score']\n",
    "non_ood_scores = df_table[df_table['OOD'] == 0]['image_score']\n",
    "plt.hist(non_ood_scores, bins=50, alpha=0.5, label='ID')\n",
    "plt.hist(ood_scores, bins=50, alpha=0.5, label='OOD')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Image Scores Distribution')\n",
    "plt.xlabel('Image Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ood_scores = df_table[df_table['OOD'] == 1]['image_score_max']\n",
    "non_ood_scores = df_table[df_table['OOD'] == 0]['image_score_max']\n",
    "plt.hist(non_ood_scores, bins=50, alpha=0.5, label='ID')\n",
    "plt.hist(ood_scores, bins=50, alpha=0.5, label='OOD')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Image Max Scores Distribution')\n",
    "plt.xlabel('Image Max Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ood_scores = df_table[df_table['OOD'] == 1]['dialogue_score']\n",
    "non_ood_scores = df_table[df_table['OOD'] == 0]['dialogue_score']\n",
    "plt.hist(non_ood_scores, bins=50, alpha=0.5, label='ID')\n",
    "plt.hist(ood_scores, bins=50, alpha=0.5, label='OOD')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Dialogue Scores Distribution')\n",
    "plt.xlabel('Dialogue Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ood_scores = df_table[df_table['OOD'] == 1]['dialogue_score_max']\n",
    "non_ood_scores = df_table[df_table['OOD'] == 0]['dialogue_score_max']\n",
    "plt.hist(non_ood_scores, bins=50, alpha=0.5, label='ID')\n",
    "plt.hist(ood_scores, bins=50, alpha=0.5, label='OOD')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Dialogue Max Scores Distribution')\n",
    "plt.xlabel('Dialogue Max Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_text_similarity(row):\n",
    "    a = row['dialogue_clip']\n",
    "    b = row['image_clip']\n",
    "    cos_sim = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "df_table['image_text_similarity'] = df_table.apply(image_text_similarity, axis=1)\n",
    "df_table['overall_simialrity'] = df_table['image_text_similarity'] * (df_table['image_score_max'] + 0.0*df_table['dialogue_score_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image Max:', ev.fpr_evaluation(df_table['OOD'].values, -df_table['image_score_max'].values, 0.95))\n",
    "print('Image Sum:', ev.fpr_evaluation(df_table['OOD'].values, -df_table['image_score'].values, 0.95))\n",
    "print('Dialogue Max:', ev.fpr_evaluation(df_table['OOD'].values, -df_table['dialogue_score_max'].values, 0.95))\n",
    "print('Dialogue Sum:', ev.fpr_evaluation(df_table['OOD'].values, -df_table['dialogue_score'].values, 0.95))\n",
    "print(\"Overall Max:\", ev.fpr_evaluation(df_table['OOD'].values, -df_table['overall_simialrity'].values, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from models.DNN import model \n",
    "\n",
    "model_loader = model.model_loader(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_ind_train, \n",
    "    df_test, \n",
    "    X_train_image, \n",
    "    X_test_image, \n",
    "    X_train_dialogue, \n",
    "    X_test_dialogue, \n",
    "    Y_train, \n",
    "    Y_test) = model_loader.create_dataset(data_loader, df_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loader.train_model(X_train_image, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_energy = -np.log(1+outputs/(1-outputs))\n",
    "outputs_energy_sum = outputs_energy.sum(axis=1)\n",
    "df_test['energy_sum'] = outputs_energy_sum\n",
    "df_test['energy_max'] = outputs_energy.min(axis=1).values.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ood_scores = df_test[df_test['OOD'] == 1]['energy_sum']\n",
    "non_ood_scores = df_test[df_test['OOD'] == 0]['energy_sum']\n",
    "\n",
    "plt.hist(non_ood_scores, bins=50, alpha=0.5, label='ID')\n",
    "plt.hist(ood_scores, bins=50, alpha=0.5, label='OOD')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.title('Energy Distribution')\n",
    "plt.xlabel('Image Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ood_scores = df_test[df_test['OOD'] == 1]['energy_max']\n",
    "non_ood_scores = df_test[df_test['OOD'] == 0]['energy_max']\n",
    "\n",
    "plt.hist(non_ood_scores, bins=50, alpha=0.5, label='ID')\n",
    "plt.hist(ood_scores, bins=50, alpha=0.5, label='OOD')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.title('Energy Distribution')\n",
    "plt.xlabel('Image Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.fpr_evaluation(df_test['OOD'].values, df_test['energy_sum'].values, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.fpr_evaluation(df_test['OOD'].values, df_test['energy_max'].values, 0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
