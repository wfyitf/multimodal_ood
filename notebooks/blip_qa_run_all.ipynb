{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json \n",
    "import sys \n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "import loaders\n",
    "from utils import scores as sc\n",
    "from utils import evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set Logger\n",
    "logger = logging.getLogger('notebook_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing one example\n",
    "# TODO: Add VSNR for cosine similarity\n",
    "data_loader = loaders.DataLoader(data_source = \"qa\", model_type='blip', logger=logger)\n",
    "df_table_origin = data_loader.load_annotations_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define OOD Categories below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 15:57:07,541 - notebook_logger - INFO - Processing OOD Category: animal\n",
      "2024-08-04 15:57:13,898 - notebook_logger - INFO - Calculating Similarity Scores\n",
      "2024-08-04 15:57:15,388 - notebook_logger - INFO - Setting random seed: 20\n",
      "2024-08-04 15:57:15,390 - notebook_logger - INFO - Setting random seed: 20\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]2024-08-04 15:57:29,429 - notebook_logger - INFO - Epoch 1, Train Loss: 0.1697, Train Accuracy: 0.5064, Test Loss: 0.1989, Test Accuracy: 0.4241\n",
      " 17%|█▋        | 1/6 [00:12<01:03, 12.64s/it]2024-08-04 15:57:42,176 - notebook_logger - INFO - Epoch 2, Train Loss: 0.1499, Train Accuracy: 0.5491, Test Loss: 0.1667, Test Accuracy: 0.5072\n",
      " 33%|███▎      | 2/6 [00:25<00:50, 12.70s/it]2024-08-04 15:57:54,811 - notebook_logger - INFO - Epoch 3, Train Loss: 0.1389, Train Accuracy: 0.5713, Test Loss: 0.1747, Test Accuracy: 0.4907\n",
      " 50%|█████     | 3/6 [00:38<00:38, 12.67s/it]2024-08-04 15:58:07,766 - notebook_logger - INFO - Epoch 4, Train Loss: 0.1390, Train Accuracy: 0.5631, Test Loss: 0.1817, Test Accuracy: 0.4542\n",
      " 67%|██████▋   | 4/6 [00:50<00:25, 12.78s/it]2024-08-04 15:58:20,359 - notebook_logger - INFO - Epoch 5, Train Loss: 0.1293, Train Accuracy: 0.5899, Test Loss: 0.1657, Test Accuracy: 0.4965\n",
      " 83%|████████▎ | 5/6 [01:03<00:12, 12.72s/it]2024-08-04 15:58:32,980 - notebook_logger - INFO - Epoch 6, Train Loss: 0.1234, Train Accuracy: 0.6041, Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "100%|██████████| 6/6 [01:16<00:00, 12.70s/it]\n",
      "2024-08-04 15:58:32,983 - notebook_logger - INFO - Model saved at f:\\Github\\multimodal_ood\\models\\DNN\\models\\DNN\\image_model_animal_6_0.001.pth\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]2024-08-04 15:58:45,483 - notebook_logger - INFO - Epoch 1, Train Loss: 0.3040, Train Accuracy: 0.2841, Test Loss: 0.4287, Test Accuracy: 0.2302\n",
      " 17%|█▋        | 1/6 [00:12<01:02, 12.48s/it]2024-08-04 15:58:57,957 - notebook_logger - INFO - Epoch 2, Train Loss: 0.2934, Train Accuracy: 0.2929, Test Loss: 0.4667, Test Accuracy: 0.1644\n",
      " 33%|███▎      | 2/6 [00:24<00:49, 12.48s/it]2024-08-04 15:59:10,466 - notebook_logger - INFO - Epoch 3, Train Loss: 0.2832, Train Accuracy: 0.2946, Test Loss: 0.4359, Test Accuracy: 0.1990\n",
      " 50%|█████     | 3/6 [00:37<00:37, 12.49s/it]2024-08-04 15:59:22,881 - notebook_logger - INFO - Epoch 4, Train Loss: 0.2776, Train Accuracy: 0.3023, Test Loss: 0.4447, Test Accuracy: 0.1830\n",
      " 67%|██████▋   | 4/6 [00:49<00:24, 12.46s/it]2024-08-04 15:59:35,364 - notebook_logger - INFO - Epoch 5, Train Loss: 0.2736, Train Accuracy: 0.3105, Test Loss: 0.4496, Test Accuracy: 0.2003\n",
      " 83%|████████▎ | 5/6 [01:02<00:12, 12.47s/it]2024-08-04 15:59:47,634 - notebook_logger - INFO - Epoch 6, Train Loss: 0.2710, Train Accuracy: 0.3186, Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "100%|██████████| 6/6 [01:14<00:00, 12.44s/it]\n",
      "2024-08-04 15:59:47,638 - notebook_logger - INFO - Model saved at f:\\Github\\multimodal_ood\\models\\DNN\\models\\DNN\\image_model_animal_6_0.001.pth\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models.DNN import model \n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "used_model = \"blip\"\n",
    "\n",
    "if used_model == \"clip\":\n",
    "    input_size = 512\n",
    "elif used_model == \"blip\":\n",
    "    input_size = 256\n",
    "\n",
    "\n",
    "category = \"animal\"\n",
    "logger.info(f\"Processing OOD Category: {category}\")\n",
    "ood_category = [category]\n",
    "ind_category = [x for x in data_loader.supercategories if x not in ood_category]\n",
    "\n",
    "df_table = df_table_origin.copy()\n",
    "df_table['OOD'] = df_table['supercategory'].apply(lambda x: 0 if any(item in x for item in ood_category) else 1)\n",
    "df_table['OOD'].value_counts()\n",
    "\n",
    "# Dialogue Processing\n",
    "dialogue_blip = np.load(f'{data_loader.data_dir}/BLIP/qa_dialogs/BLIP_imc_dialog_features.npy')\n",
    "df_table['dialogue_blip'] = list(dialogue_blip)\n",
    "## Image Processing\n",
    "df_table['image_file'] = df_table['image_id'].astype('str') + '.jpg'\n",
    "image_blip = np.load(f'{data_loader.data_dir}/BLIP/qa_imgs/BLIP_imc_image_features.npy')\n",
    "df_table['image_blip'] = list(image_blip)\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=ind_category)\n",
    "df_table['encoded_label'] = list(mlb.fit_transform(df_table['supercategory']))\n",
    "encoded_df = pd.DataFrame(df_table['encoded_label'].tolist(), columns=ind_category)\n",
    "df_table = pd.concat([df_table, encoded_df], axis=1)\n",
    "\n",
    "logger.info(f\"Calculating Similarity Scores\")\n",
    "def image_text_similarity(row):\n",
    "    a = row['dialogue_blip']\n",
    "    b = row['image_blip']\n",
    "    cos_sim = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "\n",
    "df_table['image_text_similarity'] = df_table.apply(image_text_similarity, axis=1)\n",
    "\n",
    "image_model_loader = model.model_loader(logger=logger,\n",
    "                                input_size=input_size,\n",
    "                                output_size=len(ind_category),\n",
    "                                num_epochs=6,\n",
    "                                learning_rate=0.001,\n",
    "                                proportion = 0.8,\n",
    "                                seed = 20)\n",
    "\n",
    "dialogue_model_loader = model.model_loader(logger=logger,        \n",
    "                                input_size=input_size,\n",
    "                                output_size=len(ind_category),\n",
    "                                num_epochs=6,\n",
    "                                learning_rate=0.001,\n",
    "                                seed = 20)\n",
    "\n",
    "(\n",
    "df_ind_train, \n",
    "df_test, \n",
    "X_train_image, \n",
    "X_test_image, \n",
    "X_train_dialogue, \n",
    "X_test_dialogue, \n",
    "Y_train, \n",
    "Y_test\n",
    ") = image_model_loader.create_dataset(data_loader, df_table, add_mismatch = True, mismatch_num = 20000, used_model='blip')\n",
    "\n",
    "df_test['image_text_similarity'] = df_test.apply(image_text_similarity, axis=1)\n",
    "image_model_loader.train_model(X_train_image, Y_train, X_test_image, Y_test, ood_category = '_'.join(ood_category))\n",
    "dialogue_model_loader.train_model(X_train_dialogue, Y_train, X_test_dialogue, Y_test, ood_category = '_'.join(ood_category))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 15:59:49,398 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 15:59:51,050 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 15:59:52,782 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 15:59:54,532 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 15:59:56,245 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 15:59:58,032 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 15:59:59,716 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:00:01,379 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 16:00:07,753 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:00:14,036 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 16:01:07,604 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:02:02,145 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n"
     ]
    }
   ],
   "source": [
    "score_type_list = [\"prob\", \"energy\", \"logits\", \"msp\", \"odin\", \"mahalanobis\"]\n",
    "for score_type in score_type_list:\n",
    "    if score_type != \"mahalanobis\":\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "        \n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "\n",
    "    else:\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_image,\n",
    "                                                            Y_train=Y_train)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_dialogue,\n",
    "                                                            Y_train=Y_train)\n",
    "    \n",
    "    df_test[f'{score_type}_sum_image'] = image_score_sum\n",
    "    df_test[f'{score_type}_max_image'] = image_score_max\n",
    "    df_test[f'{score_type}_sum_dialogue'] = dialogue_score_sum\n",
    "    df_test[f'{score_type}_max_dialogue'] = dialogue_score_max\n",
    "    if score_type in [\"energy\", \"logits\", \"prob\", \"odin\", \"mahalanobis\"]:\n",
    "        df_test[f'{score_type}_overall_simialrity_sum'] = df_test[f'{score_type}_sum_image'] + df_test[f'{score_type}_sum_dialogue']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 16:02:04,002 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:02:05,729 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 16:02:07,487 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:02:09,290 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 16:02:10,952 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:02:12,617 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 16:02:14,415 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:02:16,245 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 16:02:22,693 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:02:29,140 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n",
      "2024-08-04 16:03:22,857 - notebook_logger - INFO - Test Loss: 0.1641, Test Accuracy: 0.5033\n",
      "2024-08-04 16:04:17,607 - notebook_logger - INFO - Test Loss: 0.4463, Test Accuracy: 0.2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|l|c|c|c|c|}\n",
      "\\toprule\n",
      "Score & Image & Dialogue & Overall & Overall_Transform \\\\\n",
      "\\midrule\n",
      "Max Prob & 64.3 / 71.2 / 45.1 & 80.5 / 67.1 / 42.2 & 66.5 / 72.8 / 49.2 & 67.0 / 78.7 / 56.5 \\\\\n",
      "Sum Prob & 78.8 / 64.4 / 39.3 & 96.8 / 55.9 / 35.9 & 89.0 / 62.9 / 41.9 & 74.2 / 72.7 / 51.2 \\\\\n",
      "Max Logits & 64.3 / 71.2 / 45.1 & 80.5 / 67.1 / 42.2 & 65.1 / 72.5 / 49.2 & 62.9 / 80.9 / 63.8 \\\\\n",
      "Sum Logits & 95.8 / 52.9 / 33.8 & 98.1 / 41.9 / 29.3 & 98.4 / 48.9 / 34.2 & 99.1 / 40.1 / 26.5 \\\\\n",
      "Max Odin & 63.9 / 71.1 / 44.9 & 81.4 / 67.2 / 42.1 & 65.9 / 73.0 / 48.9 & 67.7 / 79.3 / 57.7 \\\\\n",
      "Sum Odin & 79.1 / 64.2 / 39.2 & 97.0 / 56.1 / 36.0 & 89.1 / 62.8 / 41.8 & 74.5 / 72.5 / 50.9 \\\\\n",
      "Max Mahalanobis & 46.9 / 77.7 / 50.6 & 81.0 / 66.9 / 40.5 & 62.1 / 77.0 / 52.3 & 52.6 / 87.7 / 75.4 \\\\\n",
      "Sum Mahalanobis & 79.7 / 71.5 / 46.2 & 92.5 / 59.0 / 35.9 & 88.2 / 66.5 / 44.3 & 67.6 / 78.7 / 61.0 \\\\\n",
      "MSP & 85.8 / 58.7 / 37.4 & 83.5 / 64.8 / 39.8 & 78.9 / 65.9 / 40.6 & 75.9 / 75.1 / 52.7 \\\\\n",
      "Energy Sum & 63.0 / 71.8 / 45.8 & 80.4 / 67.3 / 43.2 & 65.1 / 71.9 / 50.6 & 61.7 / 80.7 / 64.5 \\\\\n",
      "Energy Max & 64.3 / 71.2 / 45.1 & 80.5 / 67.1 / 42.2 & 65.6 / 72.3 / 49.0 & 62.8 / 81.0 / 63.8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_type_list = [\"prob\", \"energy\", \"logits\", \"msp\", \"odin\", \"mahalanobis\"]\n",
    "\n",
    "for score_type in score_type_list:\n",
    "    if score_type != \"mahalanobis\":\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True)\n",
    "\n",
    "    else:\n",
    "        image_score_sum, image_score_max = image_model_loader.evaluate_on_test(X_test_image, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_image,\n",
    "                                                            Y_train=Y_train)\n",
    "        dialogue_score_sum, dialogue_score_max = dialogue_model_loader.evaluate_on_test(X_test_dialogue, \n",
    "                                                            Y_test,\n",
    "                                                            score_type=score_type,\\\n",
    "                                                            return_score=True,\n",
    "                                                            X_train=X_train_dialogue,\n",
    "                                                            Y_train=Y_train)\n",
    "    \n",
    "    df_test[f'{score_type}_sum_image'] = image_score_sum\n",
    "    df_test[f'{score_type}_max_image'] = image_score_max\n",
    "    df_test[f'{score_type}_sum_dialogue'] = dialogue_score_sum\n",
    "    df_test[f'{score_type}_max_dialogue'] = dialogue_score_max\n",
    "    if score_type == \"mahalanobis\":\n",
    "        df_test[f'{score_type}_max_image_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_max_image'] \n",
    "        df_test[f'{score_type}_max_dialogue_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_max_dialogue']\n",
    "        df_test[f'{score_type}_sum_image_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_sum_image']\n",
    "        df_test[f'{score_type}_sum_dialogue_tranform'] = 4 / df_test['image_text_similarity'] * df_test[f'{score_type}_sum_dialogue'] \n",
    "    else:\n",
    "        df_test[f'{score_type}_max_image_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_max_image'] \n",
    "        df_test[f'{score_type}_max_dialogue_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_max_dialogue']\n",
    "        df_test[f'{score_type}_sum_image_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_sum_image']\n",
    "        df_test[f'{score_type}_sum_dialogue_tranform'] = 4 * df_test['image_text_similarity'] * df_test[f'{score_type}_sum_dialogue']\n",
    "    df_test[f'{score_type}_overall_simialrity_max'] = df_test[f'{score_type}_max_image'] + df_test[f'{score_type}_max_dialogue']\n",
    "    df_test[f'{score_type}_overall_simialrity_max_transform'] =  df_test[f'{score_type}_max_image_tranform'] + df_test[f'{score_type}_max_dialogue_tranform']\n",
    "    if score_type in [\"energy\", \"logits\", \"prob\", \"odin\", \"mahalanobis\"]:\n",
    "        df_test[f'{score_type}_overall_simialrity_sum'] = df_test[f'{score_type}_sum_image'] + df_test[f'{score_type}_sum_dialogue']\n",
    "        df_test[f'{score_type}_overall_simialrity_sum_transform'] = df_test[f'{score_type}_sum_image_tranform'] + df_test[f'{score_type}_sum_dialogue_tranform']\n",
    "\n",
    "\n",
    "# Initialize lists to store data\n",
    "metrics = []\n",
    "values = []\n",
    "scores = [] \n",
    "\n",
    "def eval_dict(score):\n",
    "    return {\n",
    "        \"FPR\": lambda x: ev.fpr_evaluation(x['OOD'].values, x[score].values, 0.95),\n",
    "        \"AUROC\": lambda x: ev.auroc_evaluation(x['OOD'].values, x[score].values),\n",
    "        \"AUPR\": lambda x: ev.aupr_evaluation(x['OOD'].values, x[score].values)\n",
    "    }\n",
    "\n",
    "# Define the metrics and corresponding functions\n",
    "metric_functions = {\n",
    "    \"Energy Sum\": {\n",
    "        \"Image\": eval_dict('energy_sum_image'),\n",
    "        \"Dialogue\": eval_dict('energy_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('energy_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('energy_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Energy Max\": {\n",
    "        \"Image\": eval_dict('energy_max_image'),\n",
    "        \"Dialogue\": eval_dict('energy_max_dialogue'),\n",
    "        \"Overall\": eval_dict('energy_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('energy_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"MSP\": {\n",
    "        \"Image\": eval_dict('msp_max_image'),\n",
    "        \"Dialogue\": eval_dict('msp_max_dialogue'),\n",
    "        \"Overall\": eval_dict('msp_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('msp_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Max Prob\": {\n",
    "        \"Image\": eval_dict('prob_max_image'),\n",
    "        \"Dialogue\": eval_dict('prob_max_dialogue'),\n",
    "        \"Overall\": eval_dict('prob_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('prob_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Prob\": {\n",
    "        \"Image\": eval_dict('prob_sum_image'),\n",
    "        \"Dialogue\": eval_dict('prob_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('prob_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('prob_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Odin\": {\n",
    "        \"Image\": eval_dict('odin_max_image'),\n",
    "        \"Dialogue\": eval_dict('odin_max_dialogue'),\n",
    "        \"Overall\": eval_dict('odin_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('odin_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Odin\": {\n",
    "        \"Image\": eval_dict('odin_sum_image'),\n",
    "        \"Dialogue\": eval_dict('odin_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('odin_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('odin_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Mahalanobis\": {\n",
    "        \"Image\": eval_dict('mahalanobis_max_image'),\n",
    "        \"Dialogue\": eval_dict('mahalanobis_max_dialogue'),\n",
    "        \"Overall\": eval_dict('mahalanobis_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('mahalanobis_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Mahalanobis\": {\n",
    "        \"Image\": eval_dict('mahalanobis_sum_image'),\n",
    "        \"Dialogue\": eval_dict('mahalanobis_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('mahalanobis_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('mahalanobis_overall_simialrity_sum_transform')\n",
    "    },\n",
    "    \"Max Logits\": {\n",
    "        \"Image\": eval_dict('logits_max_image'),\n",
    "        \"Dialogue\": eval_dict('logits_max_dialogue'),\n",
    "        \"Overall\": eval_dict('logits_overall_simialrity_max'),\n",
    "        \"Overall_Transform\": eval_dict('logits_overall_simialrity_max_transform')\n",
    "    },\n",
    "    \"Sum Logits\": {\n",
    "        \"Image\": eval_dict('logits_sum_image'),\n",
    "        \"Dialogue\": eval_dict('logits_sum_dialogue'),\n",
    "        \"Overall\": eval_dict('logits_overall_simialrity_sum'),\n",
    "        \"Overall_Transform\": eval_dict('logits_overall_simialrity_sum_transform')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through each metric and calculate values\n",
    "for score, items in metric_functions.items():\n",
    "    scores.extend([score] * len(items) * 3)\n",
    "    for metric, funcs in items.items():\n",
    "        metrics.extend([metric] * len(funcs))\n",
    "        values.extend([func(df_test) for func in funcs.values()])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"Metric\": metrics, \"Value\": values, \"Score\": scores})\n",
    "df['Value'] = df['Value'].apply(lambda x: round(x, 3))\n",
    "#df_grouped = df.groupby('Metric')['Value'].apply(list).reset_index()\n",
    "result = df.groupby(['Metric', 'Score'])['Value'].agg(list).unstack().transpose()\n",
    "result_df = result[['Image', 'Dialogue', 'Overall', 'Overall_Transform']]\n",
    "result_df.reset_index(inplace=True)\n",
    "order = ['Max Prob', \n",
    "         'Sum Prob', \n",
    "         'Max Logits', \n",
    "         'Sum Logits', \n",
    "         'Max Odin',\n",
    "         'Sum Odin',\n",
    "         'Max Mahalanobis',\n",
    "         'Sum Mahalanobis',\n",
    "         'MSP', \n",
    "         'Energy Sum', \n",
    "         'Energy Max']\n",
    "result_df = result_df.set_index('Score').loc[order].reset_index()\n",
    "def convert_to_percentage(lst):\n",
    "    return ' / '.join(f'{x*100:.1f}' for x in lst)\n",
    "\n",
    "result_df['Image'] = result_df['Image'].apply(convert_to_percentage)\n",
    "result_df['Dialogue'] = result_df['Dialogue'].apply(convert_to_percentage)\n",
    "result_df['Overall'] = result_df['Overall'].apply(convert_to_percentage)\n",
    "result_df['Overall_Transform'] = result_df['Overall_Transform'].apply(convert_to_percentage)\n",
    "\n",
    "latex_table = result_df.to_latex(index=False, column_format='|l|c|c|c|c|', header=[\"Score\", \"Image\", \"Dialogue\", \"Overall\", \"Overall_Transform\"], escape=False)\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
